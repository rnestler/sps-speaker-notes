---
documentclass: extarticle
fontsize: 20pt
---

# Jan Werth and Christopher Wetekamp — Even if we desperatly want to, we do not always need Deep Learning

14:25 - 14:55

 * I welcome **Jan and Christopher**
 * Dr. Jan **started** his life as a **carpenter** but switched to **Electrical
   engineering** after finding out that while construction work is fun, it is
   also hard on your back. Continuing with a PhD in the signal processing group
   he now has over 10 years of experience in DS.
 * Christopher is **Chemical Engineer** with a **passion for data**! He
   discovered coding during his master's thesis, which led him to **rejoin**
   the **university** to enroll in **Data science**.
 * They will tell us when you actually **don't need Deep Learning**, which is
   helpful since we somtimes tend to treat everything as a **nail** if we have
   a **shiny big hammer** in our toolset!

\newpage

## Biography

Dr. Jan Werth started his professional life as a carpenter. After realizing, that construction sides are fun but hard on your back, he studied Electrical engineering (EE), finishing with a PhD within the signal processing group of the TU/e (NL).
He gained his first patented Med-Tec data-science solutions while working for Philips Research in 2014. From 2018 he focussed on AI-accelerators and switched in 2020 to AI-consulting at Eraneos. 
Overall, he has well over 10 years of experience in DS.

Christopher is a Chemical Engineer at heart with a passion for data. Driven by the desire to move beyond Excel and dive into real-world problem-solving, Christopher began his coding journey during his master’s thesis and early career. His curiosity led him to rejoin the university, enrolling in a Data Science program while gaining hands-on experience in a data science company. He is now a full-time Data Scientist and loves to solve complex problems.

## Abstract

In the pursuit of classifying train stations from Open Railway Maps data, for Europe's largest rail cargo company. Initially, the project focused on developing a robust deep learning framework, which required extensive manual labeling of images to train the model effectively. Recognizing the impracticality and time-consuming nature of manual labeling, we conceptualized an approach to expedite the labeling process using cluster algorithms and graph information.
Our method involved an automated labeling algorithm, which significantly accelerated the annotation phase. This algorithm demonstrated remarkable efficiency, automatically labeling images with high accuracy, thereby drastically reducing the manual effort involved. 
During the implementation, we discovered that our automated labeling algorithm was, in itself, the comprehensive solution for the classification task we aimed to address. This realization highlighted that our initial objective of deploying a deep learning model could be achieved through “classic” means.

In conclusion, our project unveiled that the automated labeling algorithm was not just a tool to facilitate deep learning, but an effective standalone solution in itself. This unexpected outcome emphasizing that sometimes, the journey towards deep learning can reveal simpler, yet equally powerful, solutions.

Damn, as all data scientists deep down, we wanted to take advantage of some sexy deep learning and ended up with a great, but not so sexy core data science solution.
